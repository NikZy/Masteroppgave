data:
    data_path: ./datasets/raw/market_insights_overview_all_2022_02_14.csv
    categories_path: ./datasets/raw/solr_categories_all_2022_02_14.csv
logger:
    log_level: INFO
    log_file: ./log-file.log
use_gpu_if_available: no
experiment:
    tags: [market_insights]
    save_sources_to_use: [disk, neptune]
    checkpoint_save_location: ./models/0_current_model_checkpoints/
    log_model_every_n_epoch: 10
    error_metrics:
    - MASE
    - SMAPE
    - MAPE
    - MSE
    - MAE
    save_source:
        disk:
            model_save_location: ./models/
        neptune:
            project_id: sjsivertandsanderkk/Masteroppgave
model:
    model_type: local_univariate_lstm
    rng_seed: 42
    validation_model:
        placeholder: 0
    local_univariate_lstm:
        hyperparameter_tuning_range:
            hidden_size: [10, 15]
            number_of_layers: [1, 5]
            dropout: [0.0, 0.5]
            optimizer_name: [Adam, Adadelta, RMSprop]
            learning_rate: [1e-6, 1e-4]
            number_of_epochs: [5, 100]
            batch_size: 50
            input_window_size: 10
            output_window_size: 7
            multi_variable_nr: 1
            number_of_features: 1
            number_of_trials: 50
            time_to_tune_in_minutes: 60
            stateful_lstm: yes
        common_parameters_for_all_models:
            training_size: 7
            input_window_size: 10
            output_window_size: 7
            multi_variable_nr: 1
            batch_size: 50
            number_of_epochs: 51
            stateful_lstm: no
            should_shuffle_batches: yes
            optimizer_name: RMSprop
        model_structure: [{time_series_id: 2, learning_rate: 5.65e-05, hidden_layer_size: 14, dropout: 0.142, number_of_features: 1, number_of_layers: 3}]
    local_univariate_cnn_ae:
        common_parameters_for_all_models:
            training_size: 7
            input_window_size: 10
            output_window_size: 7
            multi_variable_nr: 1
            batch_size: 50
            number_of_epochs: 51
            optimizer_name: adam
            loss: mse
        model_structure: [{time_series_id: 11573, learning_rate: 0.03, encoder: [{filters: 8, kernel_size: 3, activation: relu}, {filters: 16, kernel_size: 5}], decoder: [{filters: 8, kernel_size: 5, activation: relu}, {filters: 1, kernel_size: 3}]}]
    local_univariate_cnn_ae_lstm:
        common_parameters_for_all_models:
            training_size: 7
            input_window_size: 10
            output_window_size: 7
            multi_variable_nr: 1
            batch_size: 100
            number_of_epochs: 50
            optimizer_name: adam
            loss: mse
        model_structure: [{time_series_id: 11573, learning_rate: 0.03, lstm: {learning_rate: 0.03, hidden_layer_size: 10, dropout: 0.113, number_of_features: 1, number_of_layers: 3}, encoder: [{filters: 8, kernel_size: 3, activation: relu}, {filters: 16, kernel_size: 5}], decoder: [{filters: 8, kernel_size: 5, activation: relu}, {filters: 1, kernel_size: 3}]}]
    local_univariate_arima:
        forecast_window_size: 7
        steps_to_predict: 1000
        multi_step_forecast: yes
        hyperparameter_tuning_range:
            p: [1, 10]
            d: [1, 10]
            q: [1, 10]
        metric_to_use_when_tuning: MSE
        model_structure: [{time_series_id: 2, hyperparameters: {p: 10, d: 3, q: 4}}]
