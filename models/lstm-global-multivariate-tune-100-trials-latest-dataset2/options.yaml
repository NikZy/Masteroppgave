model:
    model_config:
        global_model:
            model_structure: [{batch_size: 32, learning_rate: 7.28859370285975e-05, number_of_epochs: 21, number_of_layers: 1, optimizer_name: Adam, time_series_id: '12532,11694,11716,11950,11195,11998,274,11407,46,11326,11335,12197,11693,11780,12502,11866,11400,12256,10320,10030', layers: [{hidden_size: 93, dropout: 0.02333447649159709, recurrent_dropout: 0.14615989543469307}]}]
            datasets:
            - 12532
            - 11694
            - 11716
            - 11950
            - 11195
            - 11998
            - 274
            - 11407
            - 46
            - 11326
            - 11335
            - 12197
            - 11693
            - 11780
            - 12502
            - 11866
            - 11400
            - 12256
            - 10320
            - 10030
        hyperparameter_tuning_range:
            hidden_size: [1, 100]
            number_of_layers: [1, 1]
            dropout: [0.0, 0.4]
            recurrent_dropout: [0.0, 0.4]
            optimizer_name: [RMSprop, Adam]
            learning_rate: [1e-7, 1e-2]
            number_of_epochs: [1, 40]
            batch_size: [32, 32]
            input_window_size: 10
            output_window_size: 7
            multi_variable_nr: 4
            number_of_features: 4
            number_of_trials: 100
            stateful_lstm: yes
        local_model:
            common_parameters_for_all_models:
                input_window_size: 10
                output_window_size: 7
                multi_variable_nr: 1
                batch_size: 32
                stateful_lstm: yes
                should_shuffle_batches: no
                number_of_features: 1
            model_structure: [{time_series_id: 2, number_of_epochs: 15, optimizer_name: Adam, learning_rate: 0.00028345282219663603, hidden_layer_size: 60, dropout: 0.24970090559798974, number_of_features: 1, layers: [{hidden_size: 94, dropout: 0.21199, recurrent_dropout: 0.0}]}]
        placeholder: yes
    rng_seed: 42
    model_type: global_univariate_lstm
    config: lstm/dataset2
    validation_model:
        placeholder: yes
data:
    data_path: ./datasets/raw/market_insights_overview_all_2022_04_26.csv
    categories_path: ./datasets/raw/solr_categories_all_2022_02_14.csv
logger:
    log_level: INFO
    log_file: ./log-file.log
use_gpu_if_available: no
experiment:
    tags: [market_insights]
    save_sources_to_use: [disk, neptune]
    checkpoint_save_location: ./models/0_current_model_checkpoints/
    log_model_every_n_epoch: 10
    error_metrics:
    - MAE
    - MASE
    - MSE
    - SMAPE
    - MAPE
    save_source:
        disk:
            model_save_location: ./models/
        neptune:
            project_id: sjsivertandsanderkk/Masteroppgave
