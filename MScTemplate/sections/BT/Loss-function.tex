\subsection{Loss functions}
\label{section:BT:Loss}
\cite[p. 710-711]{Russel2012} defines loss functions as such:
A \textit{loss function} $L(x, y, \hat{y})$ is defined as the amount of utility lost by predicting 
$h(x)=\hat{y}$ when the correct answer is $f(x) = y$ and $h$ is the heuristic function.
This is the most general formulation of the loss function. Often a simplified version is used,
$L(y, \hat{y})$, that is independent of x.

This means, that the loss function is the function that calculates the error between the 
models prediction, and the actual target value.
This chapter will breafly give an explanation for common loss functions.


\todo[inline]{Burde vi skrive litt mer p√• hvert avsnitt?}
\subsubsection{MSE}
% Common loss functions
The most commonly used loss function for regression problem is the 
\textbf{Mean Squared Error (MSE)} function in \autoref{eq:mean-squared-error}.
It is the mathematically preferred function if the target distribution is Guassian.
It punishes large errors much more harshly than smaller errors, due to its squaring of the error.
Here $e = y - \hat{y}$, where $y$ is the actual value and $\hat{y}$
is the predicted value.

\begin{equation}
  \label{eq:mean-squared-error}
  MSE = \frac{1}{n} \sum_{t=1}^n e_t^2
\end{equation}

\subsubsection{MAE}
If the target distribution consists of outliers, then the 
\textbf{Mean Absolute Error (MAE)} in \autoref{eq:mean-absolute-error} is more appropriate
as it does not punish the outliers too much.

\begin{equation}
  \label{eq:mean-absolute-error}
  MSE = \frac{1}{n} \sum_{t=1}^n |e_t|
\end{equation}

\subsubsection{MAPE}
% TODO: Need source
The Mean Absolute Percentage Error \autoref{eq:Mape} (MAPE) 
is a popular metric for evaluating forecasting perfomance.
$y$ is the actual target value of the target we are trying to forecast, and $\hat{y}$ is the predicted value.
$t$ is the time index. 

The advantages of MAPE is that it is expressed as a percentage, which means
it is scale-independent and can be used for forecasting on different scales.
A percentage scale is also easily explainable.
\begin{equation}
  \label{eq:Mape}
  SMAPE = \frac{1}{n} \sum_{t=1}^n \frac{|\hat{y_t} - y_t|}{(y_t)}
\end{equation}

A big shortcomming of MAPE is that it is undefined when the actual value $y$ is 0.
It will also take extreme values if the value is close to 0.

MAPE is also asymmetric, and puts a higher penalty on errors where the predicted
$\hat{y}$ is higher than the actual value $y$.
This is because as long as we are dealing with positive numbers,
the highest bound for a low forecast is 100\%. But there is no upper limit
for forecasts that are too high. As a result the error function will
favor models that under-predict rather than over-predict a forecast.

\subsubsection{sMAPE}
Symmetric Mean Absolute Percentage Error (sMAPE) shown in \autoref{eq:sMape}
is an error function made to overcome some of the shortcommings of MAPE.
By incorporating $\hat{y}$ to the denominator sMAPE is symmetrical,
with both a lower bound of 0\% and a upper bound for 200\%.

sMAPE is still vulnerable to denominator values close to zero.

\begin{equation}
  \label{eq:sMape}
  SMAPE = \frac{1}{n} \sum_{t=1}^n \frac{|\hat{y_t} - y_t|}{(y_t + \hat{y_t}) / 2}
\end{equation}

\subsubsection{RMSE}
\subsubsection{$R^2$}


