\subsection{Loss functions}
\label{loss-functions}
A \textit{loss function} $L(x, y, \hat{y})$ is defined as the amount of utility lost by predicting 
$(h(x)=\hat{y})$ when the correct answer is $f(x) = y$ and $h$ is the heuristic function.
This is the most general formulation of the loss function. Often a simplified version is used,
$L(y, \hat{y})$, that is independent of x \cite{Russel2012}.
\todo[inline]{Burde vi skrive litt mer p√• hvert avsnitt?}
\subsubsection{MSE}
% Common loss functions
The most commonly used loss function for regression problem is the 
\textbf{Mean Squared Error (MSE)} function in \autoref{eq:mean-squared-error}.
It is the mathematically preferred function if the target distribution is Guassian.
It punishes large errors much more harshly than smaller errors, due to its squaring of the error.
\begin{equation}
  \label{eq:mean-squared-error}
  MSE = \frac{1}{n} \sum_{t=1}^n e_t^2
\end{equation}

\subsubsection{MAE}
If the target distribution consists of outliers, then the 
\textbf{Mean Absolute Error (MAE)} in \autoref{eq:mean-absolute-error} is more appropriate
as it does not punish the outliers too much.

\begin{equation}
  \label{eq:mean-absolute-error}
  MSE = \frac{1}{n} \sum_{t=1}^n |e_t|
\end{equation}

\subsubsection{sMAPE}
\todo[inline]{Trenger vi skrive om dette? }
\begin{equation}
  \label{eq:sMape}
  SMAPE = \frac{1}{n} \sum_{t=1}^n \frac{|\hat{y_t} - y_t|}{(y_t + \hat{y_t}) / 2}
\end{equation}


