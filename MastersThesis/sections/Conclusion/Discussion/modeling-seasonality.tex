
\subsection{Modeling seasonality}
Our empirical results indicate that LSTMs have trouble modeling yearly seasonality.
The dataset with the least yearly seasonality is dataset 1. This is the only dataset where
the local univariate LSTM outperformed SARIMA. However, feeding the LSTM with additional
data such as day of the week, month, and season became significantly better on datasets
with a strong seasonal component.
Our findings do not contradict the findings of \cite{Hewamalage2021} regarding NNs ability
to model seasonality [\Cref{section:Data:Preprocessing:trend-and-seasonality}]
because all their datasets have a much higher seasonal frequency. Their
data show clear seasonal patterns in a plot with 50 time steps. We have yearly seasonality
so we have to plot 365+ time steps to be able to see a seasonal pattern.

It seems LSTMs do not have long enough memory to model seasonal patterns
with a 365 timestep wavelength.
This hypothesis is supported by the findings of \cite{Zhao2020}, which concludes that
RNNs and LSTMs do not have long memory from a time series perspective.
But they do not give a definite answer for how long an LSTM remembers.

This explaines why SARIMA outperforms the local unviariate LSTM on dataset 2 and 3, as both includes
of time series with a strong seasonal dependence.
Experiment 5 [\Cref{section:results:additional-experimental-plan:Experiment-5}] where we removed
the seasonality from dataset 4 confirms this hypothesis as well. When removing the seasonal
the seasonal component the LSTM outperforms SARIMA, as we should expect.

Regarding RQ4 [\cref{RQ4}], we can conclude that on our dataset, when
both SARIMA and LSTM are given the exact same information, SARIMA will outperform
LSTM on time series with a strong 365-day seasonality because of the spatial memory limitations
of LSTMs.
SARIMA is a statistical method which does not rely on memory.
It requires the seasonal component for each time series to be known.
When a time series does not have a strong seasonal dependence or this
dependence is removed beforehand, the LSTM performs best.

%% Globale metoder gjør det bedre enn locale på MASE, men dårligere på sMAPE
% Kan det være fordi sMAPE straffer under predictions hardere enn 
% over predictions? TODO: Kjøre eksperiment på nytt for å få figures.
