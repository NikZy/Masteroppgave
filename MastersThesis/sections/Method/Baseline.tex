
\subsection{Experiment 1 - Arima baseline test}
\label{section:Method:Experiment1-Arima}

Experiment 1 is conducted to create a baseline which
the other methods can compare against. This experiment will also
answer RQ<Insert Number> \cref{TODO}.



\todo[inline]{Flytt til Goals and RQ og referer til dem her}
\begin{description}
  \item[RQ1]{\it How well will ARIMA forecast user interest in a volatile E-commerce domain using MASE and SMAPE as metrics?}
  \item[RQ1.1]{\it How many days ahead will ARIMA give a prediction that is better than the naive forecest?}
  % What are the existing solutions in problem space P? 
\end{description}
\begin{description}
  \item[RQ2]{\it How will a simple Local Univariate LSTM Neural Network compare against ARIMA baseline?}
  \item[RQ2.1]{\it Will the LSTM achieve better results for multi-step-ahead forecasting?}
  % What are the existing solutions in problem space P? 
\end{description}
\begin{description}
  \item[RQ3]{\it Will a Local Univariate Convolutional Autoencoder LSTM Neural Network outperform both ARIMA and LSTM baselines?}
  \item[RQ3.1]{\it Will a Global Univariate CNNAE-LSTM outperform a Local Univariate CNNAE-LSTM on a cluster of independent time series?}
  \item[RQ3.2]{\it Will a Local Multivariate CNNAE-LSTM outperform a Local Univariate CNNAE-LSTM on a cluster of dependent time series?}
  \item[RQ3.3]{\it Will a CNNAE-LSTM trained on a cluster of highly seasonal dependent time series generalize well to a cluster of non seasonal dependent time series?}
  % What are the existing solutions in problem space P? 
\end{description}

% What are we doing?
\subsubsection{Outline}
For each chosen category in [TODO]\cref{TODO} we are creating a Local Univariate Arima (\textbf{LUA})
model. Each model will forecast a multistep ahead prediction of 1, 3, and 7 days ahead.
We will evaluate each model with the metrics MASE and SMAPE.


% How are we conducting the experient?
\subsubsection{Parameter tuning}
\label{section:Method:Arima:Tuning}
In order to find a fitting ARIMA model for the available dataset, tuning of parameters are important.
There are several methods available for model tuning, but only a few were selected for this project.

The first method of tuning were manual tuning of parameters.
Comprised of guess work and domain konwledge, a smal sett of model parameters were tested in order to find a fitting set of parameters.
This method is time consuming, but was usefull in cases where time constraints limited the use of excessive search of parameter sets.

% TODO: The use of Excessive Grid Search withing (1,7) (1,7) (1,11)
The secound method used was excessive grid search, testing each and every set of parameters within a range of parameter values.
With the ARIMA model, three parameters are configurable. p, d and q.
The grid search was run with parameters ranging from 1 to 7 for p and q, as well as 1 to 11 for q.
This parameter range is only limited by the computational power available to the researcher, as well as the limitation of time.


% What do we expect to happen?
\subsubsection{Expectations}
As descrive in section TODO \cref{TODO} statistical models like ARIMA does
fall short on highly volatile time series.
We expect the models to outperform the naive forecast, and get a SMAPE metric
lower than 1.0 for one-step-ahead predictions.
We expect the model to show the underlying trends in the dataset, but to
undershoot its predictions.

We expect the model to perform progressively worse for multistep-ahead 3 and 7
days ahead. Our prediction is that a 3 days forecast is worse than the naive forecast.


%The ARIMA model is the first model implemented as a base-line model.
%As described in \Cref{section:BT:ARIMA}, the ARIMA model has long been a state of the art model for time sereies prediction.
%Due to this, the use of the ARIMA model as a base line, newer models can be compared to the previous state of the art model within the same problem space,
%and with the same dataset.
%With this, the first baseline model for this project is defined.

% TODO: Add references to the Codebase

%In order to achieve a baseline prediction on the selected dataset, the ARIMA model is tuned in order to achieve better predictive results.



\subsection{Results}
% TODO: Should be moved to the 'Results' chapter
The ARIMA model is created as a baseline model.
This is done in order to create a baseline prediction on the available datasets, using a well known method for time series forecasting.

Using the exchausive grid search presented in \Cref{section:Method:Arima:Tuning}, followed by manual tuning,
a set of parameters were found for the different time series in our dataset.

% TODO: Present results




