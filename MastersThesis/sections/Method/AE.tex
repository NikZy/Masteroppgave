
\subsection{Convolutional Autoencoder}
\label{section:Method:CNN-AE-LSTM:AE}

% --------------------------------------------
% __ Contents __
% What model is used?
% What dataset is used? (Is there a split?)
% Error metrics used and recorded?
% Tuning method used
% Experiments run after tuning
% Expectations from experiments
% Add which resarch questions this answers or helps to answer
% --------------------------------------------


% What model is used
As part of the hybrid convolutional autoencoder and LSTM model structure,
a convolutional autoencoder is needed.
The autoencoder is intended to encode and reconstruct the input values of a time series,
before the reconstructed values can be used as input for the LSTM model.

The model is created using 1D convolutional and trans-convolutional layers,
encoding the spacial data from the time series.



% Model selection
\subsubsection{Model selection}

In order to find a well-suited autoencoder design, manual tuning of the model was conducted.
Tuning of the model was done incrementally, with different compositions of layer types and sizes.
Using layers such as the convolutional 1-dimensional layer, dense layers, MinMaxPooling, BatchNormalization, and different dropouts,
an ideal model architecture was attempted.

After tuning the autoencoder on the different datasets with both local, global, univariate and multivariate experiments,
a shared model design was reached.
The convolutional autoencoder consists of an encoder component using 2 convolutional layers.
The first layer has a kernel size of 3, with 16 filters, while the second layer has a kernel size of 5, with 32 filters.
Similarly, the decoder is comprised of two TransConvolutional layers with kernel sizes 5 and 3, where the first layer has a filter size of 32.
The number of filters in the last layer depends on the type of model created. A univariate model has only 1 filter, as only one value of reconstructed per time point,
while the multivariate model has 4.

This model architecture ensures the data is well reconstructed,
and can be shared across all the different models.
All the chosen parameters are shown in \Cref{table:Conv1d-cell-parameters},
\Cref{table:MaxPooling1D-cell-parameters}, and
\Cref{table:conv1dtranspose-cell-parameters}.

\todo[inline]{Sander g√• over verdier og sjekke at alt er riktig?}

\begin{table}[h]
  \centering
  \caption{Conv1d cell parameters}
  \label{table:Conv1d-cell-parameters}
  \begin{tabular}{|l|l|}\hline
    Parameter             & value             \\ \hline
    \hline
    filters               & 16, 32            \\ \hline
    kernel\_size          & 3, 5              \\ \hline
    strides               & 1                 \\ \hline
    padding               & "valid"           \\ \hline
    data\_format          & "channels\_last"  \\ \hline
    dilation\_rate        & 1                 \\ \hline
    groups                & 1                 \\ \hline
    activation            & "relu"            \\ \hline
    use\_bias             & True              \\ \hline
    kernel\_initializer   & "glorot\_uniform" \\ \hline
    bias\_initializer     & "zeros"           \\ \hline
    kernel\_regularizer   & None              \\ \hline
    bias\_regularizer     & None              \\ \hline
    activity\_regularizer & None              \\ \hline
    kernel\_constraint    & None              \\ \hline
    bias\_constraint      & None              \\ \hline
    \hline
  \end{tabular}
\end{table}

\begin{table}[h]
  \centering
  \caption{MaxPooling1D cell parameters}
  \label{table:MaxPooling1D-cell-parameters}
  \begin{tabular}{|l|l|}\hline
    Parameter    & value            \\ \hline
    \hline
    pool\_size   & ??               \\ \hline
    strides      & ??               \\ \hline
    padding      & "valid"          \\ \hline
    date\_format & "channels\_last" \\ \hline
    \hline
  \end{tabular}
\end{table}
\begin{table}[h]
  \centering
  \caption{Conv1DTranspose cell parameters}
  \label{table:conv1dtranspose-cell-parameters}
  \begin{tabular}{|l|l|}\hline
    Parameter             & value                    \\ \hline
    \hline
    filters               & 32, number\_of\_features \\ \hline
    kernel\_size          & 5, 3                     \\ \hline
    strides               & 1                        \\ \hline
    padding               & "valid"                  \\ \hline
    data\_format          & "channels\_last"         \\ \hline
    dilation\_rate        & 1                        \\ \hline
    groups                & 1                        \\ \hline
    activation            & "relu"                   \\ \hline
    use\_bias             & True                     \\ \hline
    kernel\_initializer   & "glorot\_uniform"        \\ \hline
    bias\_initializer     & "zeros"                  \\ \hline
    kernel\_regularizer   & None                     \\ \hline
    bias\_regularizer     & None                     \\ \hline
    activity\_regularizer & None                     \\ \hline
    kernel\_constraint    & None                     \\ \hline
    bias\_constraint      & None                     \\ \hline
    \hline
  \end{tabular}
\end{table}



\subsubsection{Performance metric}
Due to the fact that the only aim for the autoencoder is to construct a recreation of the time series data,
it has no need for the same measure of accuracies as the SARIMA model and the LSTM model.
This is because it does not perform future predictions, and it is therefore not compared to the other models.
However, it has its own goals, which it aims to achieve.
In order to tune the autoencoder, a loss function is selected to be used during the training process.
Taking inspiration from \cite{Zhao2019}, the error metrics MAPE was selected attempted.
However, during tuning and testing of the models, the MAPE metric was found to make predictions with extremely high error values.
The same goes for the MSE metric.
Therefore, based on experimentation and results from tuning,
the MAE metric was found to be the best match for the autoencoder.


\subsubsection{Local and global models}
With the current design of the autoencoder, the aim was to find an autoencoder that works well with both local and global models.
Even though the global models are tasked with encoding more data, this was not a clear problem with the design, although there are limitations.
With highly correlating data, such as dataset 1, less data is needed to encode because partial data is shared across the different time series.
However, this is not the case for non-correlating data, such as with dataset 2.
With this, more data is needed to be encoded with the same model as above.
Although this impaired the performance of the autoencoder to some degree, testing and tuning of models found that there are minimal difference in performance between the global and local models.
Therefore, both due to limitations with time and with the results from model selection and tuning,
the same model was selected as a good fit for all cases and therefore shared across all the models.

\subsubsection{Univariate and multivariate}
Same as with the use of local and global models,
the use of univariate and multivariate models with the autoencoder served as a challenge.
The selected model needed to be able to encode and reconstruct data for both univariate and multivariate data sources.

The same autoencoder model as described above is still used for both of these cases.
Although more data is in need of encoding and reconstruction,
the current autoencoder design works well.
Due to experimentation with univariate and multivariate models,
it is found that the model works well and can be used on all methods regardless of univariate or multivariate.



% Same as with the autoencoder. More to learn for the univariate ae, but no global makes it dificult.

