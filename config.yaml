data:
  data_path: './datasets/raw/market_insights_overview_5p_full.csv'
  categories_path: './datasets/raw/solr_categories_all_16_09_2021.csv'


logger:
  log_level: 'INFO'
  log_file: './log_file.log' # Currently does nothing

experiment:
  tags:
    - market_insights
  save_sources_to_use: # Which sources the experiment should be saved to
    - 'disk'
    - 'neptune'

  checkpoint_save_location: './models/0_current_model_checkpoints/'
  log_model_every_n_epoch: 10

  # Possible metrics: MSE, MAE, MSE; MAE
  error_metrics:
    - 'SMAPE'
    - 'MASE'
    - 'MSE'
    - 'MAE'

  save_source:
    disk:
      model_save_location: './models/'

    neptune:
      project_id: 'sjsivertandsanderkk/Masteroppgave'
      # Set api token with env variable NEPTUNE_API_TOKEN
      #api_token: ${NEPTUNE_API_TOKEN}


model:
  # Model types: 'validation_model'. 'local_univariate_arima', 'local_univariate_lstm'
  model_type: 'local_univariate_lstm'
  rng_seed: 42
  validation_model:
    placeholder: 0

  local_univariate_lstm:
    hyperparameter_tuning_range:
      number_of_tuning_trials: 10
      hidden_size: [ 10, 200 ]
      number_of_layers: [ 1, 5 ]
      dropout: [ 0.0, 0.5 ]
      optimizer_name: ['Adam', 'SGD', 'RMSprop']
      learning_rate: [ 1e-5, 1e-1 ]
      number_of_epochs: [ 6, 10 ]
      batch_size: [ 1, 100 ]
      input_window_size: 1
      output_window_size: 1 # must be equal output_window_size
      number_of_features: 1 # must be equal to number of features in data
      number_of_trials: 1 # Number of tuning trials to run. The more the better.

    common_parameters_for_all_models:
      training_size: 0.7
      input_window_size: 7
      output_window_size: 1
      batch_size: 32
      optimizer_name: 'Adam'

    model_structure:
      - time_series_id: 11573
        learning_rate: 0.001
        hidden_layer_size: 64
        dropout: 0.2
        number_of_features: 1
        number_of_layers: 1

  local_univariate_arima:
    training_size: 0.8
    steps_to_predict: 1000
    multi_step_forecast: false # alternative is recursive single step
    # Ranges used for autotuning if --tune parameter is set
    hyperparameter_tuning_range:
      p: [1, 2]
      d: [1, 2]
      q: [1, 2]

    metric_to_use_when_tuning: 'MASE'

    model_structure:
      - time_series_id: 11573
        # 1
        hyperparameters:
          p: 7
          d: 2
          q: 7
      - time_series_id: 11037
        # 1
        hyperparameters:
          p: 7
          d: 2
          q: 7
